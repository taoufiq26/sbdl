[LOCAL]
spark.app.name = sbdl-local
spark.master = local[2]
spark.executor.instances = 2
spark.executor.cores = 1
spark.executor.memory = 1G
spark.sql.shuffle.partitions = 5
spark.driver.extraJavaOptions = -Dlog4j.configuration=file:log4j.properties -Dspark.yarn.app.container.log.dir=app-logs -Dlogfile.name=spark-log
; spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
[QA]
spark.app.name = sbdl-qa
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
spark.executor.cores = 5
spark.executor.memory = 10GB
spark.executor.memoryOverhead = 1GB
spark.executor.instances = 20
spark.sql.shuffle.partitions = 800
[PROD]
spark.app.name = sbdl
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
spark.executor.cores = 5
spark.executor.memory = 10GB
spark.executor.memoryOverhead = 1GB
spark.executor.instances = 20
spark.sql.shuffle.partitions = 800